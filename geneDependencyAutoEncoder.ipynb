{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Dependency Auto Encoder\n",
    "\n",
    "Evaluate the Low Rank Matrix Factorization Model with 19 learned features by training a true auto encoder with a bottle neck size of 10. In theory the auto encoder should be better because it can learn a non linear embedding. How ever it will need to learn a large number of features\n",
    "\n",
    "One of the other uses of this notebook is to debug the deep architectures. We noticed that the validation error is often bellow the training error. This suggest a bug. see the presentation presentations/status-2020-03-13.pptx for an overview of how to debug.\n",
    "\n",
    "ref:\n",
    "- [https://www.tensorflow.org/guide/keras/train_and_evaluate](https://www.tensorflow.org/guide/keras/train_and_evaluate)\n",
    "- [https://www.tensorflow.org/tutorials/keras/overfit_and_underfit](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO <ipython-input-1-94f26ec5a80a>:5 - <module>()] using logging configuration file:src/test/logging.test.ini.json\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from   setupLogging import setupLogging\n",
    "configFilePath = setupLogging( default_path='src/test/logging.test.ini.json')\n",
    "logger = logging.getLogger(\"notebook\")\n",
    "logger.info(\"using logging configuration file:{}\".format(configFilePath))\n",
    "\n",
    "from   DEMETER2.lowRankMatrixFactorizationEasyOfUse \\\n",
    "            import LowRankMatrixFactorizationEasyOfUse as LrmfEoU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"data/\"\n",
    "dataFileName = \"D2_Achilles_gene_dep_scores.tsv\"\n",
    "numFeatures = 19\n",
    "geneFilterPercent = 0.25 \n",
    "holdOutPercent = 0.40 \n",
    "easyOfUse = LrmfEoU(dataDir, dataFileName, numFeatures, geneFilterPercent, holdOutPercent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDict = easyOfUse.loadAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geneDependencies.shape:(11193, 501)\n",
      "genes.shape:(11193, 19)\n",
      "cellLines.shape:(501, 19)\n",
      "number of observed values in traning set: 3364160\n",
      "size of traning set: 5607693\n"
     ]
    }
   ],
   "source": [
    "# clean tidy version of demeter data\n",
    "Y, R, cellLinesNames, geneNames, = resultsDict[\"DEMETER2\"]\n",
    "geneDependencies = Y\n",
    "print(\"geneDependencies.shape:{}\".format(geneDependencies.shape))\n",
    "\n",
    "# trained model\n",
    "# scipy.optimize.OptimizeResult\n",
    "X, Theta, optimizeResult = resultsDict[\"LowRankMatrixFactorizationModel\"]\n",
    "genes = X\n",
    "print(\"genes.shape:{}\".format(genes.shape))\n",
    "cellLines = Theta\n",
    "print(\"cellLines.shape:{}\".format(cellLines.shape))\n",
    "\n",
    "# knockout logical filters. Use to select Y Train, Validations, and Test values\n",
    "RTrain, RValidation, RTest = resultsDict[\"filters\"]\n",
    "\n",
    "print(\"number of observed values in traning set: {}\".format(np.sum(RTrain)))\n",
    "print (\"size of traning set: {}\".format(np.size(RTrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DEMETER2.AutoEncoderModelArchitectures as aema\n",
    "\n",
    "# use tf.data Dataset instead of numpy if data does not fit into memory\n",
    "# TODO: AEDWIP: add shuffle. I do not think it will make much difference\n",
    "trainingData = np.multiply(geneDependencies, RTrain)\n",
    "validateData = np.multiply(geneDependencies, RValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#training_procedure\n",
    "# Many models train better if you gradually reduce the learning rate during training.\n",
    "BATCH_SIZE=1024\n",
    "N_TRAIN = trainingData.shape[0]\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=STEPS_PER_EPOCH*1000,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "# TODO: look at optional arguments\n",
    "def get_callbacks(name):\n",
    "  return [\n",
    "    tfdocs.modeling.EpochDots(),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=' val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(logdir/name),\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfdocs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-01e399f2107b>\u001b[0m in \u001b[0;36mget_callbacks\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   return [\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtfdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEpochDots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfdocs' is not defined"
     ]
    }
   ],
   "source": [
    "meaningOfLife = 42\n",
    "np.random.seed(meaningOfLife)\n",
    "tf.random.set_seed(meaningOfLife)\n",
    "\n",
    "\n",
    "builder = aema.AutoEncoderModelArchitectures(trainingDataShape=trainingData.shape,\n",
    "                                             encodingDimensions=19, \n",
    "                                             optimizer=adam, \n",
    "                                             loss='mean_squared_error',\n",
    "                                             metrics=['accuracy', 'mse'])\n",
    "\n",
    "\n",
    "# autoencoderModel = builder.l5Arch()\n",
    "# autoencoderModel = builder.simpleArch()\n",
    "autoencoderModel = builder.debugArch()\n",
    "\n",
    "%time history = autoencoderModel.fit(\\\n",
    "                                    trainingData, \\\n",
    "                                    trainingData, \\\n",
    "                                    batch_size=BATCH_SIZE, \\\n",
    "                                    epochs=15, \\\n",
    "                                    callbacks=get_callbacks(\"AEDWIP_NAME\"), \\\n",
    "                                    verbose=1, \\\n",
    "                                    validation_data=(validateData,validateData) )\n",
    "\n",
    "# %time history = autoencoderModel.fit(\\\n",
    "#                                     trainingData, \\\n",
    "#                                     trainingData, \\\n",
    "#                                     epochs=15, \\\n",
    "#                                     verbose=1, \\\n",
    "#                                     validation_data=(validateData,validateData) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3646"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderModel.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyper parameters:\n",
      "traningDataShape:(11193, 501) \n",
      "numFeatures:501 \n",
      "encodingDimensions:19\n",
      "optimizer:<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe3c6011350> \n",
      "loss:mean_squared_error \n",
      "metrics:['accuracy', 'mse']\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "e064 (Dense)                 (None, 3)                 1506      \n",
      "_________________________________________________________________\n",
      "bottleneck (Dense)           (None, 19)                76        \n",
      "_________________________________________________________________\n",
      "d064 (Dense)                 (None, 3)                 60        \n",
      "_________________________________________________________________\n",
      "dOut (Dense)                 (None, 501)               2004      \n",
      "=================================================================\n",
      "Total params: 3,646\n",
      "Trainable params: 3,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"hyper parameters:\\n{}\\n\".format(builder))\n",
    "autoencoderModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total training loss: 429.5982666015625\n",
      "\n",
      "total validation loss: 143.33135986328125\n"
     ]
    }
   ],
   "source": [
    "predictedTrain = autoencoderModel.predict(trainingData)\n",
    "trainingLoss = tf.keras.losses.mean_squared_error(trainingData, predictedTrain)\n",
    "print(\"\\ntotal training loss: {}\".format(np.sum(trainingLoss)))\n",
    "\n",
    "predictedVal = autoencoderModel.predict(validateData)\n",
    "validationLoss =  tf.keras.losses.mean_squared_error(validateData, predictedVal)\n",
    "print(\"\\ntotal validation loss: {}\".format(np.sum(validationLoss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1b5bba28e532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epocs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQwklEQVR4nO3df6xfdX3H8ecLCjqRH86WBNsqTIvYEQW8Q5xRcTBT+ke7ZEzaiUxC6ObEJdORYdzUYLJlOmNi1g3rJP7YFNFNbExNExVhMxZ7EWFQQtIhyBUyKnZ1jCGg7/3xPXhvLrfcw73fe7/1fp6P5Cb3nO/nfu/nfnLvs6fne8+5qSokSUvfYaOegCRpcRh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8LXlJ7kly7qjnIY2awZekRhh8NSvJpUn2Jvlxku1JXtDtT5KPJHkwyYEktyU5tXtsfZI9Sf4nyQ+T/NlovwqpP4OvJiX5LeCvgTcBJwD3Atd0D78ReB1wMnAccAHwUPfYJ4A/rKqjgVOBbyzitKV5WTbqCUgj8mbg6qr6LkCSdwP7k5wIPA4cDZwCfKeq7pzycY8Da5PcWlX7gf2LOmtpHjzCV6tewOCoHoCqepjBUfzKqvoG8HfAVuC/kmxLckw39HeB9cC9SW5I8upFnrc0ZwZfrbofeNGTG0mOAp4P/BCgqj5aVa8Efp3BqZ3Lu/27q2ojcDxwHXDtIs9bmjODr1YckeTZT74xCPXFSU5L8izgr4CbquqeJL+R5FVJjgD+F3gU+FmSI5O8OcmxVfU48BPgZyP7iqRnyOCrFTuA/5vy9lrgL4F/AR4AXgxs6sYeA3ycwfn5exmc6vnb7rG3APck+QnwR8CFizR/ad7iH0CRpDZ4hC9JjZg1+Emu7i5Auf0gjyfJR7sLWG5LcsbwpylJmq8+R/ifBNY9zePnAWu6ty3AP8x/WpKkYZs1+FV1I/DjpxmyEfh0DewCjktywrAmKEkajmFcabsSuG/K9kS374HpA5NsYfC/AI466qhXnnLKKUP49JLUjptvvvlHVbViLh87jOBnhn0z/upPVW0DtgGMjY3V+Pj4ED69JLUjyb2zj5rZMH5LZwJYPWV7FYOrGCVJh5BhBH87cFH32zpnAQeq6imncyRJozXrKZ0knwPOBpYnmQDeBxwBUFVXMbiCcT2wF3gEuHihJitJmrtZg19Vm2d5vIC3D21GkqQF4ZW2ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktSIXsFPsi7JXUn2JrlihsdfmOT6JLckuS3J+uFPVZI0H7MGP8nhwFbgPGAtsDnJ2mnD/gK4tqpOBzYBfz/siUqS5qfPEf6ZwN6quruqHgOuATZOG1PAMd37xwL3D2+KkqRh6BP8lcB9U7Ynun1TvR+4MMkEsAN4x0xPlGRLkvEk4/v27ZvDdCVJc9Un+JlhX03b3gx8sqpWAeuBzyR5ynNX1baqGquqsRUrVjzz2UqS5qxP8CeA1VO2V/HUUzaXANcCVNW3gWcDy4cxQUnScPQJ/m5gTZKTkhzJ4EXZ7dPG/AA4ByDJyxgE33M2knQImTX4VfUEcBmwE7iTwW/j3JHkyiQbumHvAi5NcivwOeCtVTX9tI8kaYSW9RlUVTsYvBg7dd97p7y/B3jNcKcmSRomr7SVpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqRK/gJ1mX5K4ke5NccZAxb0qyJ8kdST473GlKkuZr2WwDkhwObAV+G5gAdifZXlV7poxZA7wbeE1V7U9y/EJNWJI0N32O8M8E9lbV3VX1GHANsHHamEuBrVW1H6CqHhzuNCVJ89Un+CuB+6ZsT3T7pjoZODnJt5LsSrJupidKsiXJeJLxffv2zW3GkqQ56RP8zLCvpm0vA9YAZwObgX9MctxTPqhqW1WNVdXYihUrnulcJUnz0Cf4E8DqKdurgPtnGPPlqnq8qr4P3MXgHwBJ0iGiT/B3A2uSnJTkSGATsH3amOuANwAkWc7gFM/dw5yoJGl+Zg1+VT0BXAbsBO4Erq2qO5JcmWRDN2wn8FCSPcD1wOVV9dBCTVqS9Mylavrp+MUxNjZW4+PjI/nckvTLKsnNVTU2l4/1SltJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJakSv4CdZl+SuJHuTXPE0485PUknGhjdFSdIwzBr8JIcDW4HzgLXA5iRrZxh3NPAnwE3DnqQkaf76HOGfCeytqrur6jHgGmDjDOM+AHwQeHSI85MkDUmf4K8E7puyPdHt+4UkpwOrq+orT/dESbYkGU8yvm/fvmc8WUnS3PUJfmbYV794MDkM+AjwrtmeqKq2VdVYVY2tWLGi/ywlSfPWJ/gTwOop26uA+6dsHw2cCnwzyT3AWcB2X7iVpENLn+DvBtYkOSnJkcAmYPuTD1bVgapaXlUnVtWJwC5gQ1WNL8iMJUlzMmvwq+oJ4DJgJ3AncG1V3ZHkyiQbFnqCkqThWNZnUFXtAHZM2/feg4w9e/7TkiQNm1faSlIjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNaJX8JOsS3JXkr1Jrpjh8Xcm2ZPktiRfT/Ki4U9VkjQfswY/yeHAVuA8YC2wOcnaacNuAcaq6uXAF4EPDnuikqT56XOEfyawt6rurqrHgGuAjVMHVNX1VfVIt7kLWDXcaUqS5qtP8FcC903Znuj2HcwlwFdneiDJliTjScb37dvXf5aSpHnrE/zMsK9mHJhcCIwBH5rp8araVlVjVTW2YsWK/rOUJM3bsh5jJoDVU7ZXAfdPH5TkXOA9wOur6qfDmZ4kaVj6HOHvBtYkOSnJkcAmYPvUAUlOBz4GbKiqB4c/TUnSfM0a/Kp6ArgM2AncCVxbVXckuTLJhm7Yh4DnAl9I8r0k2w/ydJKkEelzSoeq2gHsmLbvvVPeP3fI85IkDZlX2kpSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSI3oFP8m6JHcl2Zvkihkef1aSz3eP35TkxGFPVJI0P7MGP8nhwFbgPGAtsDnJ2mnDLgH2V9VLgI8AfzPsiUqS5qfPEf6ZwN6quruqHgOuATZOG7MR+FT3/heBc5JkeNOUJM3Xsh5jVgL3TdmeAF51sDFV9USSA8DzgR9NHZRkC7Cl2/xpktvnMuklaDnT1qphrsUk12KSazHppXP9wD7Bn+lIveYwhqraBmwDSDJeVWM9Pv+S51pMci0muRaTXItJScbn+rF9TulMAKunbK8C7j/YmCTLgGOBH891UpKk4esT/N3AmiQnJTkS2ARsnzZmO/AH3fvnA9+oqqcc4UuSRmfWUzrdOfnLgJ3A4cDVVXVHkiuB8araDnwC+EySvQyO7Df1+Nzb5jHvpca1mORaTHItJrkWk+a8FvFAXJLa4JW2ktQIgy9JjVjw4Htbhkk91uKdSfYkuS3J15O8aBTzXAyzrcWUcecnqSRL9lfy+qxFkjd13xt3JPnsYs9xsfT4GXlhkuuT3NL9nKwfxTwXWpKrkzx4sGuVMvDRbp1uS3JGryeuqgV7Y/Ai738CvwYcCdwKrJ025o+Bq7r3NwGfX8g5jeqt51q8AXhO9/7bWl6LbtzRwI3ALmBs1PMe4ffFGuAW4Hnd9vGjnvcI12Ib8Lbu/bXAPaOe9wKtxeuAM4DbD/L4euCrDK6BOgu4qc/zLvQRvrdlmDTrWlTV9VX1SLe5i8E1D0tRn+8LgA8AHwQeXczJLbI+a3EpsLWq9gNU1YOLPMfF0mctCjime/9YnnpN0JJQVTfy9NcybQQ+XQO7gOOSnDDb8y508Ge6LcPKg42pqieAJ2/LsNT0WYupLmHwL/hSNOtaJDkdWF1VX1nMiY1An++Lk4GTk3wrya4k6xZtdourz1q8H7gwyQSwA3jH4kztkPNMewL0u7XCfAzttgxLQO+vM8mFwBjw+gWd0eg87VokOYzBXVffulgTGqE+3xfLGJzWOZvB//r+LcmpVfXfCzy3xdZnLTYDn6yqDyd5NYPrf06tqp8v/PQOKXPq5kIf4Xtbhkl91oIk5wLvATZU1U8XaW6Lbba1OBo4FfhmknsYnKPcvkRfuO37M/Llqnq8qr4P3MXgH4Clps9aXAJcC1BV3waezeDGaq3p1ZPpFjr43pZh0qxr0Z3G+BiD2C/V87Qwy1pU1YGqWl5VJ1bViQxez9hQVXO+adQhrM/PyHUMXtAnyXIGp3juXtRZLo4+a/ED4ByAJC9jEPx9izrLQ8N24KLut3XOAg5U1QOzfdCCntKphbstwy+dnmvxIeC5wBe6161/UFUbRjbpBdJzLZrQcy12Am9Msgf4GXB5VT00ulkvjJ5r8S7g40n+lMEpjLcuxQPEJJ9jcApvefd6xfuAIwCq6ioGr1+sB/YCjwAX93reJbhWkqQZeKWtJDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4GtJS3Jhku8k+V6SjyU5PMnDST6c5Lvd3x1Y0Y09rbs52W1JvpTked3+lyT5WpJbu495cZITktzYPe/tSV472q9Ump3B15LVXXp/AfCaqjqNwVWqbwaOAr5bVWcANzC4ihHg08CfV9XLgf+Ysv+fGdye+BXAbwIPAL8P7Oye9xXA9xbnq5LmbqHvlimN0jnAK4Hd3a0qfgV4EPg58PluzD8B/5rkWOC4qrqh2/8pBre4OBpYWVVfAqiqRwGS7AauTnIEcF1VGXwd8jzC11IW4FNVdVr39tKqev8M457u/iIz/jGe7g9UvA74IYN7QV0079lKC8zgayn7OnB+kuMBkvxq93eCD2NwZ1YYnJr596o6AOyfci7+LcANVfUTYCLJ73TP8awkz+me58Gq+jiDGwD2+5ui0gh58zQtaUkuAN7NIPKPA28HvsbgD6ysZ/AX1i6oqn1JTgOuAp7D4PbDF1fV/iRrGNy2enn3HL8HvBa4vNt+GLiou1e9dMgy+GpOkoer6rmjnoe02DylI0mN8AhfkhrhEb4kNcLgS1IjDL4kNcLgS1IjDL4kNeL/AebQYp0hPICSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.xlabel('epocs')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?? https://stats.stackexchange.com/a/325602\n",
    "# https://twitter.com/aureliengeron/status/1110839223878184960\n",
    "plt.title('Mean Squared Error')\n",
    "plt.xlabel('epocs')\n",
    "plt.plot(history.history['mse'], label='train')\n",
    "plt.plot(history.history['val_mse'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.xlabel('epocs')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "simpleArch()\n",
    "```\n",
    "totalLoss: 415.3407287597656\n",
    "\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "e064 (Dense)                 (None, 64)                32128     \n",
    "_________________________________________________________________\n",
    "bottleneck (Dense)           (None, 19)                1235      \n",
    "_________________________________________________________________\n",
    "d064 (Dense)                 (None, 64)                1280      \n",
    "_________________________________________________________________\n",
    "dOut (Dense)                 (None, 501)               32565     \n",
    "=================================================================\n",
    "Total params: 67,208\n",
    "Trainable params: 67,208\n",
    "Non-trainable params: 0\n",
    "```\n",
    "\n",
    "l3Arch()\n",
    "```\n",
    "totalLoss: 417.01519775390625\n",
    "\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "e128 (Dense)                 (None, 128)               64256     \n",
    "_________________________________________________________________\n",
    "e064 (Dense)                 (None, 64)                8256      \n",
    "_________________________________________________________________\n",
    "bottleneck (Dense)           (None, 19)                1235      \n",
    "_________________________________________________________________\n",
    "d064 (Dense)                 (None, 64)                1280      \n",
    "_________________________________________________________________\n",
    "d128 (Dense)                 (None, 128)               8320      \n",
    "_________________________________________________________________\n",
    "dOut (Dense)                 (None, 501)               64629     \n",
    "=================================================================\n",
    "Total params: 147,976\n",
    "Trainable params: 147,976\n",
    "Non-trainable params: 0\n",
    "_________________________\n",
    "```\n",
    "\n",
    "l5Arch()\n",
    "```\n",
    "totalLoss: 418.174072265625\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "e256 (Dense)                 (None, 256)               128512    \n",
    "_________________________________________________________________\n",
    "e128 (Dense)                 (None, 128)               32896     \n",
    "_________________________________________________________________\n",
    "e064 (Dense)                 (None, 64)                8256      \n",
    "_________________________________________________________________\n",
    "bottleneck (Dense)           (None, 19)                1235      \n",
    "_________________________________________________________________\n",
    "d064 (Dense)                 (None, 64)                1280      \n",
    "_________________________________________________________________\n",
    "d128 (Dense)                 (None, 128)               8320      \n",
    "_________________________________________________________________\n",
    "d256 (Dense)                 (None, 256)               33024     \n",
    "_________________________________________________________________\n",
    "dOut (Dense)                 (None, 501)               128757    \n",
    "=================================================================\n",
    "Total params: 342,280\n",
    "Trainable params: 342,280\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
